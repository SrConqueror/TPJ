{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ff74d3-78f7-495f-95d7-9298311d3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transcription and classification...\n",
      "File received: /private/var/folders/nt/_c8pnwkx3w7f2b_nwjfxcp0m0000gn/T/gradio/91cd0c86d53663b8274df489f2f9bed7232f3f5c/audio.wav\n",
      "Transcription segment:  Hello, good afternoon. This is my student ID 123.\n",
      "Transcription segment:  3, 2, 3, 2, 1, 3, 4. Actually, I'm facing issue with my\n",
      "Transcription segment:  that the problem that is present in my case and I wanted to book a full\n",
      "Transcription segment:  up appointment, so I'm expecting your call for the rest of the process. Thanks.\n",
      "Transcription segment:  Thank you.\n",
      "Results saved to AAA_dsad_123232134.csv\n",
      "All graphs saved in one file as AAA_dsad_123232134.png\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import whisper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "MODEL_NAME = \"openai/whisper-small\"\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=MODEL_NAME,\n",
    "    chunk_length_s=30,\n",
    "    device=device)\n",
    "\n",
    "\n",
    "emotion_classifier = pipeline(\"text-classification\",model='MilaNLProc/xlm-emo-t', return_all_scores=True)\n",
    "\n",
    "secondary_emotions_map = {\n",
    "    ('anger', 'fear'): ['Anxiety', 'Hostility'],\n",
    "    ('anger', 'joy'): ['Zeal', 'Pride'],\n",
    "    ('anger', 'sadness'): ['Bitterness', 'Resentment'],\n",
    "    ('fear', 'joy'): ['Thrill', 'Relief'],\n",
    "    ('fear', 'sadness'): ['Desperation', 'Hopelessness'],\n",
    "    ('joy', 'sadness'): ['Nostalgia', 'Melancholy'],\n",
    "    ('anger', 'fear', 'joy'): ['Exuberant Aggression', 'Fierce Excitement'],\n",
    "    ('anger', 'fear', 'sadness'): ['Despair', 'Turmoil'],\n",
    "    ('anger', 'joy', 'sadness'): ['Morose Satisfaction', 'Bittersweet Victory'],\n",
    "    ('fear', 'joy', 'sadness'): ['Complex Relief', 'Tinged Joy'],\n",
    "    ('anger', 'fear', 'joy', 'sadness'): ['Emotional Whirlwind', 'Profound Ambivalence']\n",
    "}\n",
    "\n",
    "\n",
    "def transcribe(file):\n",
    "    import soundfile as sf\n",
    "    print(\"File received:\", file)\n",
    "    if file is None:\n",
    "        raise gr.Error(\"You must provide an audio file.\")\n",
    "\n",
    "    # Read the audio file\n",
    "    data, samplerate = sf.read(file)\n",
    "    # Calculate the number of samples for 6 seconds\n",
    "    samples_per_segment = 6 * samplerate\n",
    "    total_samples = len(data)\n",
    "    \n",
    "    segment_texts = []\n",
    "    \n",
    "    try:\n",
    "        for start in range(0, total_samples, samples_per_segment):\n",
    "            end = start + samples_per_segment\n",
    "            segment = data[start:end]\n",
    "            # Write the segment to a temporary file\n",
    "            temp_file = \"temp_segment.wav\"\n",
    "            sf.write(temp_file, segment, samplerate)\n",
    "            # Process the segment\n",
    "            results = pipe(temp_file, batch_size=BATCH_SIZE)\n",
    "            text = results['text']\n",
    "            segment_texts.append(text)\n",
    "            print(\"Transcription segment:\", text)\n",
    "    except Exception as e:\n",
    "        print(\"Transcription error:\", e)\n",
    "        raise gr.Error(f\"An error occurred during transcription: {str(e)}\")\n",
    "\n",
    "    return segment_texts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def translate_and_classify(audio, first_name, last_name, student_id):\n",
    "    print(\"Starting transcription and classification...\")\n",
    "    segment_texts = transcribe(audio)\n",
    "    all_segment_emotions = []\n",
    "\n",
    "    for text in segment_texts:\n",
    "        try:\n",
    "            emotions = emotion_classifier(text)\n",
    "            detected_emotion = {emotion[\"label\"]: round(emotion[\"score\"] * 100, 2) for emotion in emotions[0]}\n",
    "            significant_emotions = {k: v for k, v in detected_emotion.items() if v > 3}\n",
    "            \n",
    "            secondary_emotions = []\n",
    "            keys = tuple(sorted(significant_emotions.keys()))\n",
    "            for key in secondary_emotions_map:\n",
    "                if all(subkey in keys for subkey in key):\n",
    "                    secondary_emotions.extend(secondary_emotions_map[key])\n",
    "            \n",
    "            all_segment_emotions.append({\n",
    "                \"primary_emotions\": detected_emotion,\n",
    "                \"secondary_emotions\": secondary_emotions\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"Classification error:\", e)\n",
    "            raise gr.Error(f\"An error occurred during emotion classification: {str(e)}\")\n",
    "\n",
    "    # Save results to CSV and plot emotions\n",
    "    csv_filename = f\"{first_name}_{last_name}_{student_id}.csv\"\n",
    "    png_filename = f\"{first_name}_{last_name}_{student_id}.png\"\n",
    "    save_results_to_csv(segment_texts, all_segment_emotions, csv_filename)\n",
    "    plot_emotions(segment_texts, all_segment_emotions, png_filename, first_name, last_name, student_id)\n",
    "\n",
    "    return segment_texts, all_segment_emotions\n",
    "\n",
    "emotion_short_forms = {\n",
    "    'Anxiety': 'ANX',\n",
    "    'Hostility': 'HST',\n",
    "    'Zeal': 'ZEA',\n",
    "    'Pride': 'PRD',\n",
    "    'Bitterness': 'BIT',\n",
    "    'Resentment': 'RES',\n",
    "    'Thrill': 'THR',\n",
    "    'Relief': 'RLF',\n",
    "    'Desperation': 'DSP',\n",
    "    'Hopelessness': 'HPL',\n",
    "    'Nostalgia': 'NST',\n",
    "    'Melancholy': 'MCH',\n",
    "    'Exuberant Aggression': 'EXA',\n",
    "    'Fierce Excitement': 'FEX',\n",
    "    'Despair': 'DSPR',\n",
    "    'Turmoil': 'TML',\n",
    "    'Morose Satisfaction': 'MSF',\n",
    "    'Bittersweet Victory': 'BV',\n",
    "    'Complex Relief': 'CRF',\n",
    "    'Tinged Joy': 'TJ',\n",
    "    'Emotional Whirlwind': 'EWH',\n",
    "    'Profound Ambivalence': 'PAM'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def plot_emotions(segment_texts, all_segment_emotions, filename, first_name, last_name, student_id):\n",
    "    primary_categories = ['anger', 'fear', 'joy', 'sadness']  # Example primary emotions\n",
    "    num_segments = len(all_segment_emotions)\n",
    "    \n",
    "    # Setup the plot for segments and primary emotions\n",
    "    fig, axs = plt.subplots(num_segments + 2, figsize=(15, 6 * (num_segments + 2)))  # +2 for primary and secondary combined\n",
    "\n",
    "    # Track overall secondary emotion frequencies\n",
    "    overall_secondary_counts = {}\n",
    "\n",
    "    # Plot individual segments\n",
    "    for i, segment_data in enumerate(all_segment_emotions):\n",
    "        axs[-1].set_title(f\"{first_name} {last_name} Reports [Confidential]\\nReport only to be viewed by SENECA COUNSELLING COMMITTEE\")\n",
    "        primary_scores = [segment_data['primary_emotions'].get(emotion, 0) for emotion in primary_categories]\n",
    "        axs[i].plot(primary_categories, primary_scores, label='Primary Emotions', marker='o', linestyle='-', color='blue')\n",
    "\n",
    "        # Plot secondary emotions based on appearance\n",
    "        secondary_scores = {emotion: segment_data['secondary_emotions'].count(emotion) for emotion in segment_data['secondary_emotions']}\n",
    "        for emotion, count in secondary_scores.items():\n",
    "            short_form = emotion_short_forms[emotion]\n",
    "            overall_secondary_counts[short_form] = overall_secondary_counts.get(short_form, 0) + count\n",
    "            axs[i].scatter([short_form] * count, [count] * count, label='Secondary Emotions', color='green', s=100)\n",
    "\n",
    "        axs[i].set_title(f\"Emotions in Segment {i+1}\")\n",
    "        axs[i].set_xlabel(\"Emotion Types\")\n",
    "        axs[i].set_ylabel(\"Counts\")\n",
    "        axs[i].legend()\n",
    "\n",
    "    # Combined graph for primary emotions\n",
    "    combined_primary = [sum([segment['primary_emotions'].get(emotion, 0) for segment in all_segment_emotions]) for emotion in primary_categories]\n",
    "    axs[-1-1].plot(primary_categories, combined_primary, label='Combined Primary Emotions', marker='o', linestyle='-', color='blue')\n",
    "    axs[-1-1].set_title(\"Combined Primary Emotions Across All Segments\")\n",
    "    axs[-1-1].set_xlabel(\"Emotion Types\")\n",
    "    axs[-1-1].set_ylabel(\"Counts\")\n",
    "    axs[-1-1].legend()\n",
    "\n",
    "    # Separate plot for combined secondary emotions\n",
    "    if overall_secondary_counts:\n",
    "        secondary_emotions = list(overall_secondary_counts.keys())\n",
    "        secondary_counts = [overall_secondary_counts[emo] for emo in secondary_emotions]\n",
    "        sorted_indices = np.argsort(secondary_emotions)\n",
    "        sorted_emotions = np.array(secondary_emotions)[sorted_indices]\n",
    "        sorted_counts = np.array(secondary_counts)[sorted_indices]\n",
    "        axs[-1].plot(sorted_emotions, sorted_counts, label='Combined Secondary Emotions', marker='o', linestyle='-', color='green')\n",
    "        axs[-1].set_ylim(0, max(sorted_counts) + 1)  # Adjust y-axis to better zoom into the data\n",
    "        axs[-1].set_xlabel(\"Short Form Emotion Types\")\n",
    "        axs[-1].set_ylabel(\"Counts\")\n",
    "        axs[-1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{first_name}_{last_name}_{student_id}.png\")\n",
    "    plt.close()\n",
    "    print(f\"All graphs saved in one file as {filename}\")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        first_name = gr.Textbox(label=\"First Name\")\n",
    "        last_name = gr.Textbox(label=\"Last Name\")\n",
    "        student_id = gr.Textbox(label=\"Student ID\")\n",
    "    with gr.Tab(\"Record Audio\"):\n",
    "        audio_input = gr.Audio(label='Record Audio Input', type=\"filepath\")\n",
    "        transcribe_button = gr.Button('Transcribe')\n",
    "\n",
    "    transcript_output = gr.Textbox(label=\"Transcription of each segment\", lines=6)\n",
    "    emotion_output = gr.Json(label=\"Detected Primary and Secondary Emotions for each segment\")\n",
    "\n",
    "    transcribe_button.click(translate_and_classify, inputs=[audio_input, first_name, last_name, student_id], outputs=[transcript_output, emotion_output])\n",
    "\n",
    "    demo.launch()\n",
    "   \n",
    "demo.launch(inbrowser=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_results_to_csv(segment_texts, all_segment_emotions, filename):\n",
    "    data = {\n",
    "        \"Segment Text\": segment_texts,\n",
    "        \"Primary Emotions\": [str(emotions[\"primary_emotions\"]) for emotions in all_segment_emotions],\n",
    "        \"Secondary Emotions\": [str(emotions[\"secondary_emotions\"]) for emotions in all_segment_emotions]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d49713-93c8-442c-abba-03a3e6bb28ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
